{
 "metadata": {
  "name": "Karl-Roth-twitter_regex",
  "signature": "sha256:6a7fc1cea3805acfd3bfcce99dfff56f603776d0133d139f9110a7ea06325d13"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "## Problem 4.3. Twitter: Regular Expressions.\n\nIn this problem, you will use regular expressions to process real Twitter data.\n\n(If you are curious where this data came from, 1,000 tweets were fetched using the search query `#informatics` on Tuesday, February 3rd, 2015, around 10pm. See [Mining the Social Web 2nd Edition](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition) by Matthew A. Russell. [twitter_to_ascii.py](https://github.com/INFO490/spring2015/tree/master/week04/twitter_to_ascii.py) on the course Github repository is a Python 2 script that collects 1,000 tweets and generates an ASCII text file of status texts.)\n\nIf you used `git clone`/`git pull` from `/data`, the path to the data file will be `/data/spring2015/week04/informatics.txt`. It's an ASCII text file, and when you first get a new data like this, it's a good idea to see how the data looks like. You have learned various ways to do this: you could write a short Python script that reads the file line by line and print them out; you could mount the data container onto a Docker container in terminal mode and use `head`; but here I'll show you how to use shell commands in IPython notebook. Open up a new IPython notebook and run\n\n```console\n%%bash\nhead /data/spring2015/week04/informatics.txt\n```\n\nThen the output will be\n```console\nRT @KirkDBorne: Feature Selection based on #MachineLearning in MRIs: http://t.co/fwdZRLaSMd Medical imaging #informatics #DataScience\nRT @vikpant: #SocialMedia #BigData #Mining May Improve Population #Health - HIA. http://t.co/YlVwRJb9rH #analytics #informatics #datascienc\nRT @vikpant: #SocialMedia #BigData #Mining May Improve Population #Health - HIA. http://t.co/YlVwRJb9rH #analytics #informatics #datascienc\nRT @vikpant: #SocialMedia #BigData #Mining May Improve Population #Health - HIA. http://t.co/YlVwRJb9rH #analytics #informatics #datascienc\nRT @vikpant: #SocialMedia #BigData #Mining May Improve Population #Health - HIA. http://t.co/YlVwRJb9rH #analytics #informatics #datascienc\nRT @vikpant: #SocialMedia #BigData #Mining May Improve Population #Health - HIA. http://t.co/YlVwRJb9rH #analytics #informatics #datascienc\nRT @KirkDBorne: Feature Selection based on #MachineLearning in MRIs: http://t.co/fwdZRLaSMd Medical imaging #informatics #DataScience\nRT @vikpant: #SocialMedia #BigData #Mining May Improve Population #Health - HIA. http://t.co/YlVwRJb9rH #analytics #informatics #datascienc\nRT @KirkDBorne: Feature Selection based on #MachineLearning in MRIs: http://t.co/fwdZRLaSMd Medical imaging #informatics #DataScience\nRT @KirkDBorne: Feature Selection based on #MachineLearning in MRIs: http://t.co/fwdZRLaSMd Medical imaging #informatics #DataScience\n```\n\nYour first is to clean up these texts since many of them contain non-alphabetical characters as well as special characters such as hashtags and @ signs, and HTTP links. Thus,\n\n- Use `re` regular expressions to write a function named `clean_statuses()` that takes a list of strings (tweets with special characters), and returns a list of strings (only clean words).\n\nTo do this, you should\n\n- Split the text into words (words in a text are separated by whitespaces),\n\nand remove all words that contain the following:\n\n- hashtags (#),\n- users (@),\n- links (begins with http),\n\nand also remove\n\n- any non-alphabetical characters (since a tweet may contain a foreign character or puntuation marks, e.g. \"MIRs:\" becomes \"MRIs\" or \"period.\" becomes \"period\").\n\nThe easiest way to do this (that I can think of) is substituting any hashtags, users, links, and non-alphabetical characters with empty strings `''` (using regular expressions, or regex), and at the end, using list comprehension to remove all the empty strings from the list.\n\nAt this point, you should\n\n- Convert everything to lower cases.\n\nand finally,\n\n- Return the list of cleaned-up words.\n\nFor example, the output of\n\n```python\nwith open('/data/spring2015/week04/informatics.txt', 'r') as f:\n    statuses = f.read().splitlines()\n    \nclean_tweets = clean_statuses(statuses[:10])\n```\n\n(the result of cleaning up the first 10 lines printed out by `head` above) should be\n\n```console\n['rt', 'feature', 'selection', 'based', 'on', 'in', 'mris', 'medical', 'imaging', 'rt', 'may', 'improve', 'population', 'hia', 'rt', 'may', 'improve', 'population', 'hia', 'rt', 'may', 'improve', 'population', 'hia', 'rt', 'may', 'improve', 'population', 'hia', 'rt', 'may', 'improve', 'population', 'hia', 'rt', 'feature', 'selection', 'based', 'on', 'in', 'mris', 'medical', 'imaging', 'rt', 'may', 'improve', 'population', 'hia', 'rt', 'feature', 'selection', 'based', 'on', 'in', 'mris', 'medical', 'imaging', 'rt', 'feature', 'selection', 'based', 'on', 'in', 'mris', 'medical', 'imaging']\n```\n\nNote that words that had #'s, @'s, numbers, or links in them are all gone now, and we have a list of nicely looking words. If you are confused about how to do some of the operations, you can simply google e.g. \"python convert string to lowercase\" or ask us questions.\n\nI'll even give you a hint: you can replace every word that contains a # with an empty string with \n\n```python\nclean_tweets = [re.sub('\\#.*', '', tweet) for tweet in tweets]\n```\n\nwhere I iterated through `tweets` using list comprehensions. We have to use `\\` before the `#` because `#` is a special character. The `.` matches any character (except newline), and `*` means zero or more repetitions. Thus, this line substitues every word in `tweets` that starts with a `#` with an empty string `''`."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import re\n\nwith open('/data/spring2015/week04/informatics.txt', 'r') as f:\n    statuses = f.read().splitlines()    ",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def clean_statuses(statuses):\n    '''\n    Takes a list of strings (twitter status texts containing special characters)\n    and returns a list with all lowercase words\n    (no words with #, @, http, or non-alphabetical characters)\n    \n    Parameters\n    __________\n    statuses: A list of str.\n    \n    Returns\n    _______\n    clean_tweets: A list of str.\n    '''\n\n    # your code goes here\n    #cleans tweets of any word starting with a #, @, http and makes the remaining characters lowercase\n    tweets = [ ((re.sub('(\\#\\w*|\\@\\w*|http.*|:|\\.|-)','',line)).lower()) for line in statuses]\n    \n    #changes from list of sentences to list of words\n    clean_tweets = [word for line in tweets for word in line.split()]\n    \n    return clean_tweets",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Now, returned from the `clean_statuses()` function is a list of nicely cleaned-up lowercase words. Next,\n\n- Write a function named `count_words()` that calculates the frequency of each word and returns a list of tuple of the form (string, int).\n\nFor example, if when you run\n\n```python\ncount_words(statuse[:10])\n```\n\nthe output should be\n\n```console\n[('rt', 10),\n ('based', 4),\n ('selection', 4),\n ('population', 6),\n ('mris', 4),\n ('imaging', 4),\n ('improve', 6),\n ('in', 4),\n ('feature', 4),\n ('on', 4),\n ('medical', 4),\n ('may', 6),\n ('hia', 6)]\n```"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def count_words(input_list):\n    '''\n    Takes a list of strings (sentences containing special characters) and returns a list of tuples (word, frequency).\n    \n    Parameters\n    __________\n    inputs_list: A list of strings.\n    \n    Returns\n    _______\n    counts: A tuple of (word, frequency)\n    '''\n    \n    # your code goes here\n    \n    #initializes dictionary of words and counts\n    counts = dict()\n    for word in input_list:\n        if word in counts:\n            counts[word] += 1\n        else:\n            counts[word] = 1\n    counts = [(v,k) for v,k in counts.items()] #converts from dictionary to list of tuples v for values k for key  \n    \n    return counts",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "input_list = clean_statuses(statuses[:10])\ncount_words(input_list)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 177,
       "text": "[('feature', 4),\n ('selection', 4),\n ('may', 6),\n ('in', 4),\n ('population', 6),\n ('hia', 6),\n ('mris', 4),\n ('rt', 10),\n ('on', 4),\n ('based', 4),\n ('improve', 6)]"
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}